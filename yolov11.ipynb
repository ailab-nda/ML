{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdzaNO3pumsDlt9xDofAOp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ailab-nda/ML/blob/main/yolov11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Yolo を用いた物体認識"
      ],
      "metadata": {
        "id": "tBxtRxn94SWR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "まず目を通して下さい --> 物体検出の仕組みに関する解説：https://deepsquare.jp/2020/09/yolo/"
      ],
      "metadata": {
        "id": "xbMKmg2rM0du"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. 準備"
      ],
      "metadata": {
        "id": "bMibOIEn4YAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install ultralytics lap pytubefix\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "id": "1ifoVLtwpKyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!yes|pip uninstall opencv-contrib-python\n",
        "#!yes|pip cache purge\n",
        "#!yes|sudo apt-get install libgtk2.0-dev and pkg-config\n",
        "#!pip install opencv-contrib-python"
      ],
      "metadata": {
        "id": "2MQ5PNWHmh7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_results(results):\n",
        "    # Process results list\n",
        "    for result in results:\n",
        "        boxes = result.boxes  # Boxes object for bounding box outputs\n",
        "        masks = result.masks  # Masks object for segmentation masks outputs\n",
        "        keypoints = result.keypoints  # Keypoints object for pose outputs\n",
        "        probs = result.probs  # Probs object for classification outputs\n",
        "        obb = result.obb  # Oriented boxes object for OBB outputs\n",
        "        result.show()  # display to screen\n",
        "        result.save(filename=\"result.jpg\")  # save to disk"
      ],
      "metadata": {
        "id": "xzYw7Qhar847"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 【参考】元画像の表示\n",
        "\n",
        "https://ultralytics.com/images/bus.jpg\n",
        "\n",
        "<img src=\"https://ultralytics.com/images/bus.jpg\" alt=\"image info\" />\n"
      ],
      "metadata": {
        "id": "PvmncpEyhTp3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 物体検出"
      ],
      "metadata": {
        "id": "7AfvS7BXqDTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolo11n.pt\")  # load an official model\n",
        "\n",
        "# Predict with the model\n",
        "results = model(\"https://ultralytics.com/images/bus.jpg\")  # predict on an image\n",
        "\n",
        "display_results(results)"
      ],
      "metadata": {
        "id": "SYNvpn6Lp3-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. セグメンテーション"
      ],
      "metadata": {
        "id": "gn-qXN72qJ4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolo11n-seg.pt\")  # load an official model\n",
        "\n",
        "# Predict with the model\n",
        "results = model(\"https://ultralytics.com/images/bus.jpg\")  # predict on an image\n",
        "\n",
        "display_results(results)"
      ],
      "metadata": {
        "id": "1dPZsUmxqIA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ポーズ検知"
      ],
      "metadata": {
        "id": "pIsg31mLqR0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolo11n-pose.pt\")  # load an official model\n",
        "\n",
        "# Predict with the model\n",
        "results = model(\"https://ultralytics.com/images/bus.jpg\")  # predict on an image\n",
        "\n",
        "display_results(results)"
      ],
      "metadata": {
        "id": "u8DrvZi1qQ7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 分類"
      ],
      "metadata": {
        "id": "vtiV37bus3WH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolo11n-cls.pt\")  # load an official model\n",
        "\n",
        "# Predict with the model\n",
        "results = model(\"https://ultralytics.com/images/bus.jpg\")  # predict on an image\n",
        "\n",
        "display_results(results)"
      ],
      "metadata": {
        "id": "iz_7rTCrs70F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Oriented Bounding Boxes (OBB)"
      ],
      "metadata": {
        "id": "gEFGEol6qa_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolo11n-obb.pt\")  # load an official model\n",
        "\n",
        "# Predict with the model\n",
        "results = model(\"https://ultralytics.com/images/boats.jpg\")  # predict on an image\n",
        "\n",
        "display_results(results)"
      ],
      "metadata": {
        "id": "MDN8s8kjqW8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. トラッキング"
      ],
      "metadata": {
        "id": "-YsIisGTtn7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load an official or custom model\n",
        "model = YOLO(\"yolo11n.pt\")  # Load an official Detect model\n",
        "\n",
        "# Perform tracking with the model\n",
        "results = model.track(\"https://youtu.be/tShhVopoGKk?si=2APoBT-0gbxkNTPD\", show=True)  # Tracking with default tracker\n",
        "\n",
        "#display_results(results)"
      ],
      "metadata": {
        "id": "wgFKhkQ2qf1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir video\n",
        "!rm video/*"
      ],
      "metadata": {
        "id": "ktU7FKNOEFGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "# 動画をアニメに変換\n",
        "def make_anime(video):\n",
        "    fig = plt.figure(figsize=(3,3))  # 表示サイズ指定\n",
        "\n",
        "    mov = []\n",
        "    for i in range(len(video)):  # フレームを1枚づつmovにアペンド\n",
        "        video[i].save(\"video/fig\"+f'{i:04}'+\".jpg\")\n",
        "        #img = Image.open(\"video/fig\"+f'{i:04}'+\".jpg\")\n",
        "        #plt.axis('off')\n",
        "        #mov.append([img])\n",
        "\n",
        "    # アニメーション作成\n",
        "    #anime = animation.ArtistAnimation(fig, mov, interval=50, repeat_delay=1000)\n",
        "    #plt.close()\n",
        "    #return anime\n",
        "\n",
        "make_anime(results)\n",
        "! yes|ffmpeg -r 1 -i '/content/video/fig%04d.jpg' -vcodec libx264 -pix_fmt yuv420p -r 1 '/content/tracking.mp4'"
      ],
      "metadata": {
        "id": "8tkh3w5RjEJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "mp4 = open('/content/tracking.mp4', 'rb').read()\n",
        "data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=\"50%\" height=\"50%\" controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\"\"\")"
      ],
      "metadata": {
        "id": "rVGuDX1_jXYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. リアルタイム認識"
      ],
      "metadata": {
        "id": "Y7E3s_EwfpZ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1 ライブラリのインストールと定数の設定"
      ],
      "metadata": {
        "id": "9e7QSTEtgRdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from base64 import b64decode, b64encode\n",
        "from google.colab.output import eval_js\n",
        "from IPython.display import display, Javascript\n",
        "from PIL import Image\n",
        "from ultralytics import YOLO\n",
        "from ultralytics.engine.results import Results\n",
        "import io\n",
        "import numpy as np\n",
        "\n",
        "MODEL_NAMES = ['yolov8n.pt', 'yolov8s.pt', 'yolov8m.pt', 'yolov8l.pt', 'yolov8x.pt']\n",
        "PRE_TRAINED_MODEL = YOLO(MODEL_NAMES[0])\n",
        "IMG_SHAPE = [640, 480]\n",
        "IMG_QUALITY = 0.8"
      ],
      "metadata": {
        "id": "Ul3s531MfvGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2 Webカメラの取り込み用関数"
      ],
      "metadata": {
        "id": "MvZaB15ugUZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def start_stream():\n",
        "    js = Javascript(f'''\n",
        "    const IMG_SHAPE = {IMG_SHAPE};\n",
        "    const IMG_QUALITY = {IMG_QUALITY};\n",
        "    ''' + '''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "\n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "\n",
        "    function removeDom() {\n",
        "        stream.getVideoTracks()[0].stop();\n",
        "        video.remove();\n",
        "        div.remove();\n",
        "        video = null;\n",
        "        div = null;\n",
        "        stream = null;\n",
        "        imgElement = null;\n",
        "        captureCanvas = null;\n",
        "        labelElement = null;\n",
        "    }\n",
        "\n",
        "    function onAnimationFrame() {\n",
        "        if (!shutdown) {\n",
        "            window.requestAnimationFrame(onAnimationFrame);\n",
        "        }\n",
        "        if (pendingResolve) {\n",
        "            var result = \"\";\n",
        "            if (!shutdown) {\n",
        "                captureCanvas.getContext('2d').drawImage(video, 0, 0, IMG_SHAPE[0], IMG_SHAPE[1]);\n",
        "                result = captureCanvas.toDataURL('image/jpeg', IMG_QUALITY)\n",
        "            }\n",
        "            var lp = pendingResolve;\n",
        "            pendingResolve = null;\n",
        "            lp(result);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    async function createDom() {\n",
        "        if (div !== null) {\n",
        "            return stream;\n",
        "        }\n",
        "\n",
        "        div = document.createElement('div');\n",
        "        div.style.border = '2px solid black';\n",
        "        div.style.padding = '3px';\n",
        "        div.style.width = '100%';\n",
        "        div.style.maxWidth = '600px';\n",
        "        document.body.appendChild(div);\n",
        "\n",
        "        const modelOut = document.createElement('div');\n",
        "        modelOut.innerHTML = \"<span>Status: </span>\";\n",
        "        labelElement = document.createElement('span');\n",
        "        labelElement.innerText = 'No data';\n",
        "        labelElement.style.fontWeight = 'bold';\n",
        "        modelOut.appendChild(labelElement);\n",
        "        div.appendChild(modelOut);\n",
        "\n",
        "        video = document.createElement('video');\n",
        "        video.style.display = 'block';\n",
        "        video.width = div.clientWidth - 6;\n",
        "        video.setAttribute('playsinline', '');\n",
        "        video.onclick = () => { shutdown = true; };\n",
        "        stream = await navigator.mediaDevices.getUserMedia(\n",
        "            {video: { facingMode: \"environment\"}});\n",
        "        div.appendChild(video);\n",
        "\n",
        "        imgElement = document.createElement('img');\n",
        "        imgElement.style.position = 'absolute';\n",
        "        imgElement.style.zIndex = 1;\n",
        "        imgElement.onclick = () => { shutdown = true; };\n",
        "        div.appendChild(imgElement);\n",
        "\n",
        "        const instruction = document.createElement('div');\n",
        "        instruction.innerHTML =\n",
        "            '<span style=\"color: red; font-weight: bold;\">' +\n",
        "            'When finished, click here or on the video to stop this demo</span>';\n",
        "        div.appendChild(instruction);\n",
        "        instruction.onclick = () => { shutdown = true; };\n",
        "\n",
        "        video.srcObject = stream;\n",
        "        await video.play();\n",
        "\n",
        "        captureCanvas = document.createElement('canvas');\n",
        "        captureCanvas.width = IMG_SHAPE[0]; //video.videoWidth;\n",
        "        captureCanvas.height = IMG_SHAPE[1]; //video.videoHeight;\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "\n",
        "        return stream;\n",
        "    }\n",
        "    async function takePhoto(label, imgData) {\n",
        "        if (shutdown) {\n",
        "            removeDom();\n",
        "            shutdown = false;\n",
        "            return '';\n",
        "        }\n",
        "\n",
        "        var preCreate = Date.now();\n",
        "        stream = await createDom();\n",
        "\n",
        "        var preShow = Date.now();\n",
        "        if (label != \"\") {\n",
        "            labelElement.innerHTML = label;\n",
        "        }\n",
        "\n",
        "        if (imgData != \"\") {\n",
        "            var videoRect = video.getClientRects()[0];\n",
        "            imgElement.style.top = videoRect.top + \"px\";\n",
        "            imgElement.style.left = videoRect.left + \"px\";\n",
        "            imgElement.style.width = videoRect.width + \"px\";\n",
        "            imgElement.style.height = videoRect.height + \"px\";\n",
        "            imgElement.src = imgData;\n",
        "        }\n",
        "\n",
        "        var preCapture = Date.now();\n",
        "        var result = await new Promise((resolve, reject) => pendingResolve = resolve);\n",
        "        shutdown = false;\n",
        "\n",
        "        return {\n",
        "            'create': preShow - preCreate,\n",
        "            'show': preCapture - preShow,\n",
        "            'capture': Date.now() - preCapture,\n",
        "            'img': result,\n",
        "        };\n",
        "    }\n",
        "    ''')\n",
        "    display(js)\n",
        "\n",
        "def take_photo(label, img_data):\n",
        "    data = eval_js(f'takePhoto(\"{label}\", \"{img_data}\")')\n",
        "    return data"
      ],
      "metadata": {
        "id": "AxrwXtiQf2xF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.3 使用する関数の定義"
      ],
      "metadata": {
        "id": "X-GG0AnNgnaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def js_response_to_image(js_response) -> Image.Image:\n",
        "    _, b64_str = js_response['img'].split(',')\n",
        "    jpeg_bytes = b64decode(b64_str)\n",
        "    image = Image.open(io.BytesIO(jpeg_bytes))\n",
        "    return image\n",
        "\n",
        "def turn_non_black_pixels_visible(rgba_compatible_array: np.ndarray) -> np.ndarray:\n",
        "    rgba_compatible_array[:, :, 3] = (rgba_compatible_array.max(axis=2) > 0).astype(int) * 255\n",
        "    return rgba_compatible_array\n",
        "\n",
        "def black_transparent_rgba_canvas(w, h) -> np.ndarray:\n",
        "    return np.zeros([w, h, 4], dtype=np.uint8)\n",
        "\n",
        "def draw_annotations_on_transparent_bg(detection_result: Results) -> Image.Image:\n",
        "    black_rgba_canvas = black_transparent_rgba_canvas(*detection_result.orig_shape)\n",
        "    transparent_canvas_with_boxes_invisible = detection_result.plot(font='verdana', masks=False, img=black_rgba_canvas)\n",
        "    transparent_canvas_with_boxes_visible = turn_non_black_pixels_visible(transparent_canvas_with_boxes_invisible)\n",
        "    image = Image.fromarray(transparent_canvas_with_boxes_visible, 'RGBA')\n",
        "    return image"
      ],
      "metadata": {
        "id": "oCzdAnZMgACU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.4 リアルタイム認識の実施"
      ],
      "metadata": {
        "id": "ZnrniAxagvmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_stream()\n",
        "img_data = ''\n",
        "while True:\n",
        "    js_response = take_photo('Capturing...', img_data)\n",
        "    if not js_response:\n",
        "        break\n",
        "    captured_img = js_response_to_image(js_response)\n",
        "    for detection_result in PRE_TRAINED_MODEL(source=np.array(captured_img), verbose=False):\n",
        "        annotations_img = draw_annotations_on_transparent_bg(detection_result)\n",
        "        with io.BytesIO() as buffer:\n",
        "            annotations_img.save(buffer, format='png')\n",
        "            img_as_base64_str = str(b64encode(buffer.getvalue()), 'utf-8')\n",
        "            img_data = f'data:image/png;base64,{img_as_base64_str}'"
      ],
      "metadata": {
        "id": "n0fw3FBXgDSr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}