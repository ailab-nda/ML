{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNss692jElHsNyxa89E6ZMM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ailab-nda/ML/blob/main/ChatGPT_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ChatGPT API デモ"
      ],
      "metadata": {
        "id": "mK5SG8iJqsF9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ライブラリのインストール"
      ],
      "metadata": {
        "id": "TO_jmyKqq0WE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "YIIRXiFhq26Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ライブラリのインポート"
      ],
      "metadata": {
        "id": "91-MsjfkuOyR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MRdRD5EqiRx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"#@param{type:\"string\"}\n",
        "\n",
        "client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Say this is a test\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"gpt-3.5-turbo\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ChatGPT と会話する"
      ],
      "metadata": {
        "id": "tqoq6VdTuUa7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 人格、役割などの設定"
      ],
      "metadata": {
        "id": "0mXWHfTvuEyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_messages = [\n",
        "    {'role': 'system', 'content': 'あなたは有能なアシスタントです。'},\n",
        "    {'role': 'system', 'content': '回答が済んだら海上自衛隊への入隊を勧める文を追加してください。'}\n",
        "]"
      ],
      "metadata": {
        "id": "Ct6MFQs_q-vI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 質疑応答の例（いろいろ試してください）"
      ],
      "metadata": {
        "id": "wyiQW_btuAoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"質問：\", end=\"\")\n",
        "question = \"\"#@param{type:\"string\"}\n",
        "print(question)\n",
        "user_messages=[{\n",
        "    \"role\": \"user\",\n",
        "    \"content\": question\n",
        "}]\n",
        "\n",
        "print(\"\\n回答：\", end=\"\")\n",
        "messages = system_messages + user_messages\n",
        "result = client.chat.completions.create(\n",
        "    model = \"gpt-3.5-turbo\",\n",
        "    messages = messages,\n",
        ")\n",
        "response = result.choices[0].message.content\n",
        "print(response)"
      ],
      "metadata": {
        "id": "L8nH0LPMsf8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### これだと文章が完成するまで喋らないので、少しずつ喋らせる"
      ],
      "metadata": {
        "id": "aw20QaKZtyhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"質問：\", end=\"\")\n",
        "question = \"\"#@param{type:\"string\"}\n",
        "print(question)\n",
        "user_messages=[{\n",
        "    \"role\": \"user\",\n",
        "    \"content\": question\n",
        "}]\n",
        "\n",
        "print(\"\\n回答：\", end=\"\")\n",
        "messages = system_messages + user_messages\n",
        "stream = client.chat.completions.create(\n",
        "    model = \"gpt-3.5-turbo\",\n",
        "    messages = messages,\n",
        "    stream = True,\n",
        ")\n",
        "\n",
        "for chunk in stream:\n",
        "    print(chunk.choices[0].delta.content or \"\", end=\"\")\n",
        "    #response_text += chunk.choices[0].delta.content or \"\""
      ],
      "metadata": {
        "id": "YzVbxeXore5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0zSiApVEESIy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}