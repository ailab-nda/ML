{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ailab-nda/ML/blob/main/WebScraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv2Y7Ebnrrtz"
      },
      "source": [
        "# 演習III 第１回 Web スクレイピング\n",
        "\n",
        "出典　https://code.dividable.net/tutorials/python-scraping-blog/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMkQzXdArrt1"
      },
      "source": [
        "## 1. モジュールのインストールとインポート"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZlm_aL9rrt2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "import time\n",
        "import random\n",
        "import re\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mv6eO0Ymrrt2"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SENXR5Jwrrt2"
      },
      "source": [
        "## 2. BeautifulSoup の初期化\n",
        "\n",
        "BeautifulSoupで、HTMLを読み込みます。本来は、外部サイトのHTMLを取得して、そのデータを受け取りますが、学習のため、こちらで用意したHTMLを利用してみたいと思います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLTg7zB8rrt2"
      },
      "outputs": [],
      "source": [
        "# こちらで用意したHTML\n",
        "html_doc = \"\"\"\n",
        "<html><head><title>The Dormouse's story</title></head>\n",
        "<body>\n",
        "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
        "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
        "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
        "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
        "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
        "and they lived at the bottom of a well.</p>\n",
        "<p class=\"story\">...</p>\n",
        "\"\"\"\n",
        "# BeautifulSoupの初期化\n",
        "soup = BeautifulSoup(html_doc, 'html.parser') # BeautifulSoupの初期化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CArob93rrt2"
      },
      "outputs": [],
      "source": [
        "print(soup.prettify()) # HTMLをインデントすることができます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzuLE6pqrrt2"
      },
      "source": [
        "## 3. BeautifulSoupでtitleを取得\n",
        "\n",
        "BeautifulSoupを利用する方法はいたってシンプルです。\n",
        "\n",
        "titleタグの内容を取りたい場合は、soup.titleで取得できます。\n",
        "\n",
        "例： \\<title\\>The Dormouse’s story\\</title\\>\n",
        "\n",
        " titleタグの中身の文字だけを取りたい場合は、soup.title.stringで取得できます。\n",
        "\n",
        "例：The Dormouse’s story\n",
        "\n",
        "さっそく試してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGrcMpX3rrt2"
      },
      "outputs": [],
      "source": [
        "# <title>The Dormouse's story</title>を取得してください。\n",
        "print(soup.title)\n",
        "# The Dormouse's story を取得してください。\n",
        "print(soup.title.string)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BewBI1cOrrt2"
      },
      "source": [
        "## 4. BeautifulSoupで複数のaタグを取得\n",
        "\n",
        "では、今度は同じタグが複数存在する場合も見てみましょう。現状、aタグは3つあります。これらのタグをすべて取りたいです。そこで、このaタグを取ろうとして、soup.aを試すと、最初の一つだけとることになり、すべてを取ることができません。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpNFOxo8rrt2"
      },
      "outputs": [],
      "source": [
        "print(soup.a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Gos1woyrrt2"
      },
      "source": [
        "そこで、今回は複数のタグを取る find_all メソッドを利用して、複数タグを取得します。 soup.find_all(‘a’)のように指定すると、リスト形式ですべてのaタグを取得することができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6I33QyGrrt2"
      },
      "outputs": [],
      "source": [
        "soup.find_all(\"a\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcvnlV_irrt2"
      },
      "source": [
        "それでは、取得したaタグのリンクを一つ一つ取り出してみましょう。リストの中から、一つ一つaタグを取得していきます。\n",
        "\n",
        "## TODO\n",
        "1. for文を利用して、取得したaタグのHTMLを含む部分をprintしてください。\n",
        "2. for文を利用して、取得したaタグのHTMLを含まない部分だけprintしてください。\n",
        "ヒント\n",
        "1. リスト形式のデータは、for 単数 in リスト 構文を利用して、一つひとつ取り出すことができます。\n",
        "2. HTMLを含まない中身をとるものは、stringを利用するのでした。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaCZksorrrt2"
      },
      "outputs": [],
      "source": [
        "tags = soup.find_all(\"a\")\n",
        "# for文を利用して、取得したaタグのHTMLを含む部分をprintしてください。\n",
        "print(\"1. \")\n",
        "for tag in tags:\n",
        "   print (tag)\n",
        "# for文を利用して、取得したaタグのHTMLを含む部分をprintしてください。\n",
        "print(\"2. \")\n",
        "for tag in tags:\n",
        "   print (tag.string)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZLgAffVrrt3"
      },
      "source": [
        "## 5. BeautifulSoupでURLの取得\n",
        "\n",
        "今度は、取得したaタグのhrefに当たる部分、つまりURLだけとりだしてみましょう。soup.a.get(“href”)のように指定することで、URLを取得することができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIXtfUHOrrt3"
      },
      "outputs": [],
      "source": [
        "soup.a.get(\"href\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXNBWQjvrrt3"
      },
      "source": [
        "それでは、さきほど取得したaタグのすべてのURLをprintしてみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxzoK0K8rrt3"
      },
      "outputs": [],
      "source": [
        "# TODO1 for文を利用して、aタグのURLをすべてprintしてください\n",
        "for link in tags:\n",
        " print (link.get(\"href\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-QC-SC7rrt3"
      },
      "source": [
        "# 実際のサイトをスクレイピングしてみよう"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_A48tairrt3"
      },
      "source": [
        "## 1. Requests: WebページのHTMLを取得しよう\n",
        "下記のページから、記事のタイトルと、その記事のURLを取得してみましょう。実際にWebページからデータを取得するのは、requestsというライブラリを利用します。 requestsをimportします。requests.get(url)でurlのページの情報を取得し、textを実行するとHTMLの内容を取得することができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuuT3ZJRrrt3"
      },
      "outputs": [],
      "source": [
        "response = requests.get(\"https://review-of-my-life.blogspot.com/\")\n",
        "print (response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PX6NQ8Evrrt3"
      },
      "outputs": [],
      "source": [
        "html_doc = response.text\n",
        "soup = BeautifulSoup(html_doc, 'html.parser') # BeautifulSoupの初期化\n",
        "print(soup.prettify())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDr_sdmrrrt3"
      },
      "source": [
        "## pandas: CSVにデータを保存しよう"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCbFVcZxrrt3"
      },
      "source": [
        "### TODO\n",
        "- 記事名と記事URLをすべて取得し、CSVに出力してください。\n",
        "- データフレームを作成してください。列名は、name, urlです。\n",
        "- 記事名と記事URLをデータフレームに追加してください\n",
        "- result.csvという名前でCSVに出力してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0kPlJzdrrt3"
      },
      "outputs": [],
      "source": [
        "# 記事名と記事URLの取得\n",
        "tags = soup.find_all(\"h3\",{\"class\":\"post-title\"})\n",
        "print(tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rW5F_AScrrt3"
      },
      "outputs": [],
      "source": [
        "# データフレームを作成してください。列名は、name, urlです。\n",
        "columns = [\"name\", \"url\"]\n",
        "df = pd.DataFrame(columns=columns)\n",
        "# 記事名と記事URLをデータフレームに追加してください\n",
        "for tag in tags:\n",
        " name = tag.a.string\n",
        " url = tag.a.get(\"href\")\n",
        " se = pd.Series([name, url], columns)\n",
        " print(se)\n",
        " df = pd.concat([df, pd.DataFrame([se])], ignore_index=True)\n",
        "# result.csvという名前でCSVに出力してください。\n",
        "filename = \"result.csv\"\n",
        "df.to_csv(filename, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpqKYp74rrt3"
      },
      "source": [
        "# 課題\n",
        "売れているノートパソコンは大体いくら位のものか？スクレイピングを利用して調べよ。"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xKefVPbUtG39"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "dcf9e2717909001467cf879b1089e6e80dddbfb5060f305c8aadf7a9adff89a8"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}