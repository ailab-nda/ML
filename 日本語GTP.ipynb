{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "日本語GTP.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMt+sCEeDzZCktB5glEmCib",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ailab-nda/NLP/blob/main/%E6%97%A5%E6%9C%AC%E8%AA%9EGTP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 日本語GTPによる自然言語語処理"
      ],
      "metadata": {
        "id": "Al5z5vvgY0dP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 背景 \n",
        "最近のNLPに関する研究では、モデルのパラメータ数が多いほど高い性能を発揮することが知られています。実際、英語においては、人間が作る文章とAIが作る文章の区別が付かないほどですが、日本語はその特殊性から英語ほど研究が進んでいません。そこで本演習では、現在フリーで使用できるモデルのうち、最も大規模な13億パラメータを持つ日本語に特化したGPT言語モデルを使用し、日本語における自然言語処理の現状を認識してもらいます。\n"
      ],
      "metadata": {
        "id": "wLoVQ7WOZRdi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 準備１（関連ライブラリのインストール）"
      ],
      "metadata": {
        "id": "yei2UYWwapKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "tddu1AyzMDOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 準備２（関連ライブラリのインポート）"
      ],
      "metadata": {
        "id": "M2ksmhtRaxpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained(\"rinna/japanese-gpt-1b\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"rinna/japanese-gpt-1b\")"
      ],
      "metadata": {
        "id": "veNzgyiFL380"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 準備３（GPUの使用）"
      ],
      "metadata": {
        "id": "4m3DQJuea7QQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    model = model.to(\"cuda\")"
      ],
      "metadata": {
        "id": "Qe3Z3Dw6L6H6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 演習"
      ],
      "metadata": {
        "id": "VTTNnP4bbEhE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 文章の生成\n",
        "書き出しを入力することで、続きの文章を生成します。"
      ],
      "metadata": {
        "id": "fjjiuEJSbHQT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 文章を生成する関数の定義\n",
        "gtp モデルの generate 関数を呼び出すことで行います。"
      ],
      "metadata": {
        "id": "FyPpRoiwV_Ke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sentense(question):\n",
        "    token_ids = tokenizer.encode(text, add_special_tokens=False, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(\n",
        "            token_ids.to(model.device),\n",
        "            max_length=100,\n",
        "            min_length=100,\n",
        "            do_sample=True,\n",
        "            top_k=500,\n",
        "            top_p=0.95,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "            bos_token_id=tokenizer.bos_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "            bad_word_ids=[[tokenizer.unk_token_id]]\n",
        "        )\n",
        "    output = tokenizer.decode(output_ids.tolist()[0])\n",
        "    return output"
      ],
      "metadata": {
        "id": "cxzx3NdNXk_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 文章生成の例１"
      ],
      "metadata": {
        "id": "IngDtJ3gbhaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"私が御社を志望したのは、\"\n",
        "answer = generate_sentense(text)\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "l0e9IDKjWkFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 文書生成の例２\n",
        "上記の text の内容を変えて、違う書き出しで文章を作成させてみましょう。"
      ],
      "metadata": {
        "id": "UEnZa5YVblRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\" # ここを自分の例にする\n",
        "answer = generate_sentense(text)\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "pDluAismbunR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 質問とその答え\n",
        "文章生成関数をちょっと作り替えると、質問に対する答えを生成してくれる関数が作れます。"
      ],
      "metadata": {
        "id": "tQyBVrdMb6s3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 質疑応答用関数\n",
        "上で作った generate_sentense の出力の余計な部分をカットするだけです。"
      ],
      "metadata": {
        "id": "z9ns1J5lcUsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def q_and_a(question):\n",
        "    output = generate_sentense(question)\n",
        "    output2 = output[len(text):]\n",
        "    return(output2[:output2.find('。')+1])"
      ],
      "metadata": {
        "id": "PlW4fDXAV98B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 例１：テキストの分類\n",
        "例をいくつか挙げて、最後に聞いたものがどちらに当てはまるかを答えさせます。"
      ],
      "metadata": {
        "id": "gO6MpmY2SE4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"「最悪」はネガティブな言葉。「いいね」はポジティブな言葉。「素晴らしい」はポジティブな言葉。「良くはない」は\"\n",
        "answer = q_and_a(text)\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "xGrpi9ybPKni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 例２：翻訳\n",
        "英語と日本語の対を与えて、最後の英語がどのような日本語に対応するかを答えさせます。"
      ],
      "metadata": {
        "id": "OCUcv_8ASKK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Helloは、こんにちはという意味です。Good morningは、おはようという意味です。Thank youは、\"\n",
        "answer = q_and_a(text)\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "2t1X-GewSIjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 例３：やってみよう\n",
        "上記の text の内容を変えて、違う例を作成してみましょう。"
      ],
      "metadata": {
        "id": "xQCE9DMSd4Br"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\" # ここを自分の例にする\n",
        "answer = q_and_a(text)\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "yODA41YWYNwe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}