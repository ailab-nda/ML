{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ailab-nda/ML/blob/main/yolov11_webcam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Yolo を用いた（リアルタイム）物体認識"
      ],
      "metadata": {
        "id": "tBxtRxn94SWR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. 準備"
      ],
      "metadata": {
        "id": "bMibOIEn4YAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install ultralytics lap pytubefix\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "id": "1ifoVLtwpKyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. ライブラリのインストールと定数の設定"
      ],
      "metadata": {
        "id": "9e7QSTEtgRdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from base64 import b64decode, b64encode\n",
        "from google.colab.output import eval_js\n",
        "from IPython.display import display, Javascript\n",
        "from PIL import Image\n",
        "from ultralytics import YOLO\n",
        "from ultralytics.engine.results import Results\n",
        "import io\n",
        "import numpy as np\n",
        "\n",
        "MODEL_NAMES = ['yolo11n.pt', 'yolo11s.pt', 'yolo11m.pt', 'yolo11l.pt', 'yolo11x.pt']\n",
        "PRE_TRAINED_MODEL = YOLO(MODEL_NAMES[0])\n",
        "IMG_SHAPE = [640, 480]\n",
        "IMG_QUALITY = 0.8"
      ],
      "metadata": {
        "id": "Ul3s531MfvGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Webカメラの取り込み用関数"
      ],
      "metadata": {
        "id": "MvZaB15ugUZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def start_stream():\n",
        "    js = Javascript(f'''\n",
        "    const IMG_SHAPE = {IMG_SHAPE};\n",
        "    const IMG_QUALITY = {IMG_QUALITY};\n",
        "    ''' + '''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "\n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "\n",
        "    function removeDom() {\n",
        "        stream.getVideoTracks()[0].stop();\n",
        "        video.remove();\n",
        "        div.remove();\n",
        "        video = null;\n",
        "        div = null;\n",
        "        stream = null;\n",
        "        imgElement = null;\n",
        "        captureCanvas = null;\n",
        "        labelElement = null;\n",
        "    }\n",
        "\n",
        "    function onAnimationFrame() {\n",
        "        if (!shutdown) {\n",
        "            window.requestAnimationFrame(onAnimationFrame);\n",
        "        }\n",
        "        if (pendingResolve) {\n",
        "            var result = \"\";\n",
        "            if (!shutdown) {\n",
        "                captureCanvas.getContext('2d').drawImage(video, 0, 0, IMG_SHAPE[0], IMG_SHAPE[1]);\n",
        "                result = captureCanvas.toDataURL('image/jpeg', IMG_QUALITY)\n",
        "            }\n",
        "            var lp = pendingResolve;\n",
        "            pendingResolve = null;\n",
        "            lp(result);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    async function createDom() {\n",
        "        if (div !== null) {\n",
        "            return stream;\n",
        "        }\n",
        "\n",
        "        div = document.createElement('div');\n",
        "        div.style.border = '2px solid black';\n",
        "        div.style.padding = '3px';\n",
        "        div.style.width = '100%';\n",
        "        div.style.maxWidth = '600px';\n",
        "        document.body.appendChild(div);\n",
        "\n",
        "        const modelOut = document.createElement('div');\n",
        "        modelOut.innerHTML = \"<span>Status: </span>\";\n",
        "        labelElement = document.createElement('span');\n",
        "        labelElement.innerText = 'No data';\n",
        "        labelElement.style.fontWeight = 'bold';\n",
        "        modelOut.appendChild(labelElement);\n",
        "        div.appendChild(modelOut);\n",
        "\n",
        "        video = document.createElement('video');\n",
        "        video.style.display = 'block';\n",
        "        video.width = div.clientWidth - 6;\n",
        "        video.setAttribute('playsinline', '');\n",
        "        video.onclick = () => { shutdown = true; };\n",
        "        stream = await navigator.mediaDevices.getUserMedia(\n",
        "            {video: { facingMode: \"environment\"}});\n",
        "        div.appendChild(video);\n",
        "\n",
        "        imgElement = document.createElement('img');\n",
        "        imgElement.style.position = 'absolute';\n",
        "        imgElement.style.zIndex = 1;\n",
        "        imgElement.onclick = () => { shutdown = true; };\n",
        "        div.appendChild(imgElement);\n",
        "\n",
        "        const instruction = document.createElement('div');\n",
        "        instruction.innerHTML =\n",
        "            '<span style=\"color: red; font-weight: bold;\">' +\n",
        "            'When finished, click here or on the video to stop this demo</span>';\n",
        "        div.appendChild(instruction);\n",
        "        instruction.onclick = () => { shutdown = true; };\n",
        "\n",
        "        video.srcObject = stream;\n",
        "        await video.play();\n",
        "\n",
        "        captureCanvas = document.createElement('canvas');\n",
        "        captureCanvas.width = IMG_SHAPE[0]; //video.videoWidth;\n",
        "        captureCanvas.height = IMG_SHAPE[1]; //video.videoHeight;\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "\n",
        "        return stream;\n",
        "    }\n",
        "    async function takePhoto(label, imgData) {\n",
        "        if (shutdown) {\n",
        "            removeDom();\n",
        "            shutdown = false;\n",
        "            return '';\n",
        "        }\n",
        "\n",
        "        var preCreate = Date.now();\n",
        "        stream = await createDom();\n",
        "\n",
        "        var preShow = Date.now();\n",
        "        if (label != \"\") {\n",
        "            labelElement.innerHTML = label;\n",
        "        }\n",
        "\n",
        "        if (imgData != \"\") {\n",
        "            var videoRect = video.getClientRects()[0];\n",
        "            imgElement.style.top = videoRect.top + \"px\";\n",
        "            imgElement.style.left = videoRect.left + \"px\";\n",
        "            imgElement.style.width = videoRect.width + \"px\";\n",
        "            imgElement.style.height = videoRect.height + \"px\";\n",
        "            imgElement.src = imgData;\n",
        "        }\n",
        "\n",
        "        var preCapture = Date.now();\n",
        "        var result = await new Promise((resolve, reject) => pendingResolve = resolve);\n",
        "        shutdown = false;\n",
        "\n",
        "        return {\n",
        "            'create': preShow - preCreate,\n",
        "            'show': preCapture - preShow,\n",
        "            'capture': Date.now() - preCapture,\n",
        "            'img': result,\n",
        "        };\n",
        "    }\n",
        "    ''')\n",
        "    display(js)\n",
        "\n",
        "def take_photo(label, img_data):\n",
        "    data = eval_js(f'takePhoto(\"{label}\", \"{img_data}\")')\n",
        "    return data"
      ],
      "metadata": {
        "id": "AxrwXtiQf2xF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 使用する関数の定義"
      ],
      "metadata": {
        "id": "X-GG0AnNgnaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def js_response_to_image(js_response) -> Image.Image:\n",
        "    _, b64_str = js_response['img'].split(',')\n",
        "    jpeg_bytes = b64decode(b64_str)\n",
        "    image = Image.open(io.BytesIO(jpeg_bytes))\n",
        "    return image\n",
        "\n",
        "def turn_non_black_pixels_visible(rgba_compatible_array: np.ndarray) -> np.ndarray:\n",
        "    # Ensure the input is RGBA. If it's RGB, add an alpha channel.\n",
        "    if rgba_compatible_array.shape[2] == 3:\n",
        "        h, w, _ = rgba_compatible_array.shape\n",
        "        temp_rgba = np.zeros((h, w, 4), dtype=np.uint8)\n",
        "        temp_rgba[:, :, :3] = rgba_compatible_array  # Copy RGB channels\n",
        "        rgba_compatible_array = temp_rgba\n",
        "\n",
        "    # Set alpha channel for non-black pixels\n",
        "    rgba_compatible_array[:, :, 3] = (rgba_compatible_array.max(axis=2) > 0).astype(int) * 255\n",
        "    return rgba_compatible_array\n",
        "\n",
        "def black_transparent_rgba_canvas(w, h) -> np.ndarray:\n",
        "    return np.zeros([w, h, 4], dtype=np.uint8)\n",
        "\n",
        "def draw_annotations_on_transparent_bg(detection_result: Results) -> Image.Image:\n",
        "    black_rgba_canvas = black_transparent_rgba_canvas(*detection_result.orig_shape)\n",
        "\n",
        "    # Plot detections; this often returns a 3-channel (RGB) image, even if input was 4-channel\n",
        "    plotted_img_rgb = detection_result.plot(font='verdana', masks=False, img=black_rgba_canvas)\n",
        "\n",
        "    # Ensure the image is 4-channel RGBA before passing to turn_non_black_pixels_visible\n",
        "    # The turn_non_black_pixels_visible function now handles the RGB to RGBA conversion if needed.\n",
        "    transparent_canvas_with_boxes_visible = turn_non_black_pixels_visible(plotted_img_rgb)\n",
        "\n",
        "    image = Image.fromarray(transparent_canvas_with_boxes_visible, 'RGBA')\n",
        "    return image"
      ],
      "metadata": {
        "id": "oCzdAnZMgACU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. リアルタイム認識の実施"
      ],
      "metadata": {
        "id": "ZnrniAxagvmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_stream()\n",
        "img_data = ''\n",
        "while True:\n",
        "    js_response = take_photo('Capturing...', img_data)\n",
        "    if not js_response:\n",
        "        break\n",
        "    captured_img = js_response_to_image(js_response)\n",
        "    for detection_result in PRE_TRAINED_MODEL(source=np.array(captured_img), verbose=False):\n",
        "        annotations_img = draw_annotations_on_transparent_bg(detection_result)\n",
        "        with io.BytesIO() as buffer:\n",
        "            annotations_img.save(buffer, format='png')\n",
        "            img_as_base64_str = str(b64encode(buffer.getvalue()), 'utf-8')\n",
        "            img_data = f'data:image/png;base64,{img_as_base64_str}'"
      ],
      "metadata": {
        "id": "n0fw3FBXgDSr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}