{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ailab-nda/NLP/blob/main/Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1zY4P3XUM2e"
      },
      "source": [
        "# 日本語学習済みモデルによる自然言語処理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KW1W5AOUowz"
      },
      "source": [
        "### 準備（関連ライブラリのインストール）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h5Y7k8e3WQy"
      },
      "source": [
        "!pip install -q transformers\n",
        "!pip install -q sentencepiece\n",
        "!pip install -q datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1snol5wIUawe"
      },
      "source": [
        "## 1. RoBERTa による文章中の空欄埋め\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ta1Zf-gUxJA"
      },
      "source": [
        "### モデルのダウンロード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDMZTkNRRvkl"
      },
      "source": [
        "from transformers import T5Tokenizer, RobertaForMaskedLM\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"rinna/japanese-roberta-base\")\n",
        "tokenizer.do_lower_case = True  # due to some bug of tokenizer config loading\n",
        "\n",
        "model = RobertaForMaskedLM.from_pretrained(\"rinna/japanese-roberta-base\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYo4P-RpU1g3"
      },
      "source": [
        "### 問題文の作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bG_y3KX3R9Fo"
      },
      "source": [
        "# original text\n",
        "text = \"4年に1度オリンピックは開かれる。\"\n",
        "#text = \"\"\n",
        "\n",
        "# prepend [CLS]\n",
        "text = \"[CLS]\" + text\n",
        "\n",
        "# tokenize\n",
        "tokens = tokenizer.tokenize(text)\n",
        "print(tokens)\n",
        "\n",
        "# mask a token\n",
        "masked_idx = 5\n",
        "tokens[masked_idx] = tokenizer.mask_token\n",
        "print(tokens) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lao7fOXYU_df"
      },
      "source": [
        "### 穴埋め問題を解く"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XHqe2k4WPt8"
      },
      "source": [
        "補充すべき単語の推定 (id)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfCfwo7vSOmb"
      },
      "source": [
        "# convert to ids\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(token_ids)\n",
        "\n",
        "# convert to tensor\n",
        "import torch\n",
        "token_tensor = torch.LongTensor([token_ids])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8s6nSS5YWZhy"
      },
      "source": [
        "結果の表示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBBgnyLhSgpf"
      },
      "source": [
        "# provide position ids explicitly\n",
        "position_ids = list(range(0, token_tensor.size(1)))\n",
        "position_id_tensor = torch.LongTensor([position_ids])\n",
        "\n",
        "# get the top 10 predictions of the masked token\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids=token_tensor, position_ids=position_id_tensor)\n",
        "    predictions = outputs[0][0, masked_idx].topk(10)\n",
        "\n",
        "for i, index_t in enumerate(predictions.indices):\n",
        "    index = index_t.item()\n",
        "    token = tokenizer.convert_ids_to_tokens([index])[0]\n",
        "    print(i, token)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pla_3YxVN_g"
      },
      "source": [
        "## 2. GPT-2 による文書生成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz2_A1zdkE3X"
      },
      "source": [
        "### (1) rinna/japanese-gpt2 の利用"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THovObjOV18G"
      },
      "source": [
        "### モデルのダウンロード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYr-6Sk4RXBb"
      },
      "source": [
        "from transformers import T5Tokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"rinna/japanese-gpt2-medium\")\n",
        "tokenizer.do_lower_case = True  # due to some bug of tokenizer config loading\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"rinna/japanese-gpt2-medium\")"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xoa-OUqiWECt"
      },
      "source": [
        "### 文書生成の例"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuj3d3wOE_cJ"
      },
      "source": [
        "input = tokenizer.encode(\"私が防衛大学校に入校してから、\", return_tensors=\"pt\")\n",
        "output = model.generate(input, do_sample=True, max_length=100, num_return_sequences=3)\n",
        "sentences = tokenizer.batch_decode(output)\n",
        "for i in sentences:\n",
        "    print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJNI3s4Dk0l_"
      },
      "source": [
        "ここで、train.txt と run_clm.py のアップロードを行う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEotsURZgNfq"
      },
      "source": [
        "%%time\n",
        "!rm -r output\n",
        "\n",
        "# ファインチューニングの実行\n",
        "!python ./run_clm.py \\\n",
        "    --model_name_or_path=rinna/japanese-gpt2-small \\\n",
        "    --train_file=train.txt \\\n",
        "    --validation_file=train.txt \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --num_train_epochs=10 \\\n",
        "    --save_steps=5000 \\\n",
        "    --save_total_limit=3 \\\n",
        "    --per_device_train_batch_size=2 \\\n",
        "    --per_device_eval_batch_size=2 \\\n",
        "    --output_dir=output/ \\\n",
        "    --use_fast_tokenizer=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXZQf15Sgeik"
      },
      "source": [
        "# モデルの準備\n",
        "model = AutoModelForCausalLM.from_pretrained(\"output/\")\n",
        "\n",
        "# 推論\n",
        "input = tokenizer.encode(\"おはよう、お兄ちゃん。\", return_tensors=\"pt\")\n",
        "output = model.generate(input, do_sample=True, max_length=100, num_return_sequences=8)\n",
        "sentences = tokenizer.batch_decode(output)\n",
        "for i in sentences:\n",
        "    print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfnrGkVoj-5j"
      },
      "source": [
        "## (2) GPT2-Japanese の利用"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1PcyX7Qku14"
      },
      "source": [
        "### モデルのダウンロードとインストール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvM-z3pdOZEi"
      },
      "source": [
        "# gpt2-japaneseのインストール\n",
        "!git clone https://github.com/tanreinama/gpt2-japanese\n",
        "%cd gpt2-japanese\n",
        "#!pip uninstall tensorflow -y\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC2ExWNabCeH"
      },
      "source": [
        "# smallモデルのダウンロード\n",
        "!wget https://www.nama.ne.jp/models/gpt2ja-small.tar.bz2\n",
        "!tar xvfj gpt2ja-small.tar.bz2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAcoVLUgk5Rt"
      },
      "source": [
        "### ランダムな文章の作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcDL1l6hdUNX"
      },
      "source": [
        "# smallモデルの動作確認\n",
        "!python gpt2-generate.py --model gpt2ja-small --num_generate 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Lp-WPCTk1ph"
      },
      "source": [
        "### 文章の続きを作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYG-XCyHebGa"
      },
      "source": [
        "!python gpt2-generate.py --model gpt2ja-small --num_generate 3 --context=\"私は防衛大学校に入校してから、\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaUhdN9recTk"
      },
      "source": [
        "# データセットの作成\n",
        "!git clone https://github.com/tanreinama/Japanese-BPEEncoder.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Hg24DNNm0e4"
      },
      "source": [
        "ここで、gtp2-japanese の下に mydata というフォルダを作成し、データを置く。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuxnmlayoG-g"
      },
      "source": [
        "!python ./Japanese-BPEEncoder/encode_bpe.py --src_dir mydata --dst_file finetune"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqCmn2uYwJ6K"
      },
      "source": [
        "ここで、run_finetune.py を gtp2-japanese の下に置く。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAwSANKXoPtU"
      },
      "source": [
        "!python run_finetune.py --base_model gpt2ja-small --dataset finetune.npz --run_name gpr2ja-finetune_run1-small"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qL2paV3RppP2"
      },
      "source": [
        "!python gpt2-generate.py --model checkpoint/gpr2ja-finetune_run1-small --num_generate 8"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}