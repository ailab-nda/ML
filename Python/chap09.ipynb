{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ailab-nda/ML/blob/main/Python/chap09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhTJVPjB_hUe"
      },
      "source": [
        "# 第9章 深層学習\n",
        "\n",
        "ディープニューラルネットワークを用いて識別問題をコーディングします。Google ColabでGPUを使用するときは、「ランタイム」->「ランタイムのタイプを変更」-> ハードウェアアクセラレータ -> GPU を選びます。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "深層学習用ラッパーライブラリ Keras は、ver3.0 からバックエンドとして TensorFlow, JAX, PyTorch が選べるマルチバックエンドになります。この notebook では、その pre-release である [Keras Core](https://github.com/keras-team/keras-core) でコーディングを行います。"
      ],
      "metadata": {
        "id": "55PvtcOmlO7j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "事前のインストール"
      ],
      "metadata": {
        "id": "oK4vIQzImccY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-core transformers"
      ],
      "metadata": {
        "id": "i8F3l1pNmbne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJufnsl7zZEx"
      },
      "source": [
        "## 畳み込みネットワークによる画像認識"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpzpLYDY_hUg"
      },
      "source": [
        "## 準備\n",
        "\n",
        "必要なライブラリ等を読み込みます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD7cellA4t5f"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras_core as keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データの読み込み"
      ],
      "metadata": {
        "id": "1dji7Mmtvk6F"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Bg2omPRuJrH"
      },
      "source": [
        "fasion MNISTデータ（学習用60000事例、評価用10000事例、それぞれ28x28の行列）を使います。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cYgrGTTuJrH"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 正解ラベル\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag','Ankle boot']"
      ],
      "metadata": {
        "id": "4zAV752Ve7Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNQD9y15DJxX"
      },
      "source": [
        "# いくつかの画像を表示\n",
        "plt.gray()\n",
        "fig, axs = plt.subplots(3, 3)\n",
        "for i in range(3):\n",
        "  for j in range(3):\n",
        "    axs[i,j].axis(\"off\")\n",
        "    axs[i,j].set_title(class_names[y_train[i*3+j]])\n",
        "    axs[i,j].imshow(X_train[i*3+j])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91ohTe6AuJrI"
      },
      "source": [
        "入力を3次元テンソルから4次元テンソルに変換します。各次元は、データ数、縦のピクセル数、横のピクセル数、チャネル数（グレースケール画像は1）を表します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssF4xTgCuJrI"
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0] , 28, 28, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecZucGesDJxg"
      },
      "source": [
        "値のとりうる範囲を0-255から0-1に変換します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HQokv1oDJxg"
      },
      "source": [
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCsl_iwmDJxj"
      },
      "source": [
        "まず、通常の3階層ネットワークで学習・評価します。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = keras.Sequential([\n",
        "    keras.layers.Input(shape=(28, 28, 1)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model1.summary()"
      ],
      "metadata": {
        "id": "wJ87yEbRnfse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "損失関数の `sparse_categorical_crossentropy` は正解ラベルが整数で与えられているときに用います。one-hotベクトルで与えられている場合は `categorical_crossentropy`です。"
      ],
      "metadata": {
        "id": "Gj3YsL06unnu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qSEizYkDJxl"
      },
      "source": [
        "model1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2weM0IVwVuH"
      },
      "source": [
        "学習時の各エポックで検証用データを使ったスコアがログに記録されます。`validation_split` を設定すると、学習用データの中から指定した割合に応じて検証用データが作成されます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzZGhqeHwVuI"
      },
      "source": [
        "model1.fit(X_train, y_train, epochs=5, batch_size=200, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "評価用データで性能を評価します"
      ],
      "metadata": {
        "id": "FiUH8BeSxEQG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrFUnTVGDJxn"
      },
      "source": [
        "test_loss, test_acc = model1.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {test_acc:.4}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAiTQ-WeDJxp"
      },
      "source": [
        "畳み込みネットワークで学習します。モデルのパラメータ数で構造を確認してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BWatikRDJxq"
      },
      "source": [
        "model2 = keras.Sequential([\n",
        "    keras.layers.Input(shape=(28, 28, 1)),\n",
        "    keras.layers.Conv2D(16, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3CNQjzmDJxt"
      },
      "source": [
        "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fit(X_train, y_train, epochs=5, batch_size=200, validation_split=0.1)"
      ],
      "metadata": {
        "id": "MZaKJzAMxU2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFewZVvQDJxv"
      },
      "source": [
        "test_loss, test_acc = model2.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {test_acc:.4}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE4y3RCMuJrJ"
      },
      "source": [
        "Dropoutを入れます。ユニットの半数が消えている状態で学習を行うので、epochは倍の回数をとります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dyeh9bkBuJrJ"
      },
      "source": [
        "model3 = keras.Sequential([\n",
        "    keras.layers.Input(shape=(28, 28, 1)),\n",
        "    keras.layers.Conv2D(16, kernel_size=(3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model3.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm9KH2fhuJrJ"
      },
      "source": [
        "model3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model3.fit(X_train, y_train, epochs=10, batch_size=200, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiGKpq24uJrJ"
      },
      "source": [
        "評価用データで評価します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwgSwjeTuJrJ"
      },
      "source": [
        "test_loss, test_acc = model3.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {test_acc:.4}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_BEK_G-z7uS"
      },
      "source": [
        "## リカレントニューラルネットワークによる自然言語処理\n",
        "\n",
        "IMDBデータは映画のレビューに対して、P/N(肯定/否定)のラベルが付いた学習データです。学習用に25000事例、評価用に25000事例用意されていて、PNの割合はそれぞれ50%です。\n",
        "各レビューは単語列ではなく、単語インデックスの系列として表現されています。\n",
        "\n",
        "ここでは、頻度上位10000語を対象とし、データの大きさは先頭の50単語に限定します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYd0gsbUpkgU"
      },
      "source": [
        "## 準備\n",
        "\n",
        "必要なライブラリ等を読み込みます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WejK0oS_pkgZ"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras_core as keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6DQZd3QzZE5"
      },
      "source": [
        "max_features = 10000\n",
        "maxlen = 50\n",
        "(X_train, y_train), (X_test, y_test) = keras.datasets.imdb.load_data(num_words=max_features)\n",
        "X_train = keras.preprocessing.sequence.pad_sequences(X_train, maxlen=maxlen)\n",
        "X_test = keras.preprocessing.sequence.pad_sequences(X_test, maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nFoIxKpzZE5"
      },
      "source": [
        "単語インデックスを単語に戻して、元のデータを確認します。インデックスは\"padding\", \"start of sequence\",\"unknown\"にそれぞれ0,1,2が割り当てられているので、3つずらして対応させます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu6JqeV9zZE5"
      },
      "source": [
        "word_index = keras.datasets.imdb.get_word_index()\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in X_train[0]])\n",
        "decoded_review"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-j2xNJazZE6"
      },
      "source": [
        "単純なRNNを構成して学習させます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYvOYT6ZzZE6"
      },
      "source": [
        "model1 = keras.Sequential([\n",
        "    keras.layers.Input(shape=(50,)),\n",
        "    keras.layers.Embedding(max_features, 128),\n",
        "    keras.layers.SimpleRNN(64),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_nr4RhmzZE6"
      },
      "source": [
        "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "model1.fit(X_train, y_train, epochs=2, batch_size=32, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haV1G1n2zZE6"
      },
      "source": [
        "test_loss, test_acc = model1.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {test_acc:.4}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "双方向LSTMを試します。"
      ],
      "metadata": {
        "id": "_Oxht2HTy3XV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = keras.Sequential([\n",
        "    keras.layers.Input(shape=(50,)),\n",
        "    keras.layers.Embedding(max_features, 128),\n",
        "    keras.layers.Bidirectional(keras.layers.LSTM(64)),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model2.summary()"
      ],
      "metadata": {
        "id": "M2m4NLOdy3hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "model2.fit(X_train, y_train, epochs=2, batch_size=32,validation_split=0.1)"
      ],
      "metadata": {
        "id": "l76ZbK5azm_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model2.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {test_acc:.4}')"
      ],
      "metadata": {
        "id": "YxnJo_5pznDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 事前学習モデルを用いた識別\n",
        "\n",
        "transformersライブラリを用いて、BERTでPN判定を行います。pipelineインスタンス作成時にタスクを与えると、デフォルトの設定が適用されます。また、モデルを与えると、そのモデルの設定が適用されます。あとは、そのインスタンスに入力を与えるだけで、結果が返却されます。"
      ],
      "metadata": {
        "id": "t6sYYHT7fo-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "nlp = pipeline('sentiment-analysis')\n",
        "\n",
        "sentences = [\n",
        "    \"I love this movie, it's amazing and I had a great time.\",  # ポジティブな文\n",
        "    \"I am having a bad experience with this story. It's borning.\" # ネガティブな文\n",
        "]\n",
        "\n",
        "for sentence in sentences:\n",
        "    result = nlp(sentence)\n",
        "    print(f\"Text: {sentence}\")\n",
        "    print(f\"Sentiment: {result}\\n\")"
      ],
      "metadata": {
        "id": "aUF3TjegfpJy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}