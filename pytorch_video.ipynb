{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "name": "7_1_6_audio_preprocessing_tutorial_jp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ailab-nda/NLP/blob/main/pytorch_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning による物体追跡"
      ],
      "metadata": {
        "id": "WXcA6TvHcAmI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "本日の授業は課題付与ですが、内容はこのノートを実行することとなります。"
      ],
      "metadata": {
        "id": "26vJpsh8x01I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 準備"
      ],
      "metadata": {
        "id": "JKp41A1MeJeD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ライブラリのインストール"
      ],
      "metadata": {
        "id": "ZAVj0FoscMlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn==0.22.2 filterpy==1.1.0"
      ],
      "metadata": {
        "id": "jD-5kPWVtG6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### プログラムのダウンロード"
      ],
      "metadata": {
        "id": "AsZ65zRFcSMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/cfotache/pytorch_objectdetecttrack.git\n",
        "% cd pytorch_objectdetecttrack/config/\n",
        "! bash download_weights.sh"
      ],
      "metadata": {
        "id": "36v2n74uqkMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ライブラリのインポート"
      ],
      "metadata": {
        "id": "2p2lsVHAcd6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "% cd /content/pytorch_objectdetecttrack"
      ],
      "metadata": {
        "id": "FZbV91MFtaBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from models import *\n",
        "from utils import *\n",
        "\n",
        "import os, sys, time, datetime, random\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "K2J5P6SRqz4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### モデル(Yolo) のセットアップ"
      ],
      "metadata": {
        "id": "7DzIBIMkczVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config_path='config/yolov3.cfg'\n",
        "weights_path='config/yolov3.weights'\n",
        "class_path='config/coco.names'\n",
        "img_size=416\n",
        "conf_thres=0.8\n",
        "nms_thres=0.4\n",
        "\n",
        "# Load model and weights\n",
        "model = Darknet(config_path, img_size=img_size)\n",
        "model.load_weights(weights_path)\n",
        "model.cuda()\n",
        "model.eval()\n",
        "classes = utils.load_classes(class_path)\n",
        "Tensor = torch.cuda.FloatTensor"
      ],
      "metadata": {
        "id": "7-j2P2Srq55v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 物体検出用関数の定義"
      ],
      "metadata": {
        "id": "2FJEraBNd0nD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_image(img):\n",
        "    # scale and pad image\n",
        "    ratio = min(img_size/img.size[0], img_size/img.size[1])\n",
        "    imw = round(img.size[0] * ratio)\n",
        "    imh = round(img.size[1] * ratio)\n",
        "    img_transforms = transforms.Compose([ transforms.Resize((imh, imw)),\n",
        "         transforms.Pad((max(int((imh-imw)/2),0), max(int((imw-imh)/2),0), max(int((imh-imw)/2),0), max(int((imw-imh)/2),0)),\n",
        "                        (128,128,128)),\n",
        "         transforms.ToTensor(),\n",
        "         ])\n",
        "    # convert image to Tensor\n",
        "    image_tensor = img_transforms(img).float()\n",
        "    image_tensor = image_tensor.unsqueeze_(0)\n",
        "    input_img = Variable(image_tensor.type(Tensor))\n",
        "    # run inference on the model and get detections\n",
        "    with torch.no_grad():\n",
        "        detections = model(input_img)\n",
        "        detections = utils.non_max_suppression(detections, 80, conf_thres, nms_thres)\n",
        "    return detections[0]"
      ],
      "metadata": {
        "id": "S0wE29V4rFi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 物体検出"
      ],
      "metadata": {
        "id": "1QS2aWnfd7eA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pytorch_objectdetectrack の中の中の images にサンプルイメージが入っています。Intersection-Counts.jpg 以外でも試してみてください。"
      ],
      "metadata": {
        "id": "LPjGGefdeSjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load image and get detections\n",
        "img_path = \"images/Intersection-Counts.jpg\"\n",
        "prev_time = time.time()\n",
        "img = Image.open(img_path)\n",
        "detections = detect_image(img)\n",
        "inference_time = datetime.timedelta(seconds=time.time() - prev_time)\n",
        "print ('Inference Time: %s' % (inference_time))\n",
        "\n",
        "# Get bounding-box colors\n",
        "cmap = plt.get_cmap('tab20b')\n",
        "colors = [cmap(i) for i in np.linspace(0, 1, 20)]\n",
        "\n",
        "img = np.array(img)\n",
        "plt.figure()\n",
        "fig, ax = plt.subplots(1, figsize=(12,9))\n",
        "ax.imshow(img)\n",
        "\n",
        "pad_x = max(img.shape[0] - img.shape[1], 0) * (img_size / max(img.shape))\n",
        "pad_y = max(img.shape[1] - img.shape[0], 0) * (img_size / max(img.shape))\n",
        "unpad_h = img_size - pad_y\n",
        "unpad_w = img_size - pad_x\n",
        "\n",
        "if detections is not None:\n",
        "    unique_labels = detections[:, -1].cpu().unique()\n",
        "    n_cls_preds = len(unique_labels)\n",
        "    bbox_colors = random.sample(colors, n_cls_preds)\n",
        "    # browse detections and draw bounding boxes\n",
        "    for x1, y1, x2, y2, conf, cls_conf, cls_pred in detections:\n",
        "        box_h = ((y2 - y1) / unpad_h) * img.shape[0]\n",
        "        box_w = ((x2 - x1) / unpad_w) * img.shape[1]\n",
        "        y1 = ((y1 - pad_y // 2) / unpad_h) * img.shape[0]\n",
        "        x1 = ((x1 - pad_x // 2) / unpad_w) * img.shape[1]\n",
        "        color = bbox_colors[int(np.where(unique_labels == int(cls_pred))[0])]\n",
        "        bbox = patches.Rectangle((x1, y1), box_w, box_h, linewidth=2, edgecolor=color, facecolor='none')\n",
        "        ax.add_patch(bbox)\n",
        "        plt.text(x1, y1, s=classes[int(cls_pred)], color='white', verticalalignment='top',\n",
        "                bbox={'color': color, 'pad': 0})\n",
        "plt.axis('off')\n",
        "# save image\n",
        "plt.savefig(img_path.replace(\".jpg\", \"-det.jpg\"), bbox_inches='tight', pad_inches=0.0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GZPYrFglrImJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 物体追跡"
      ],
      "metadata": {
        "id": "isjivgz7ekUi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "動画の長さは１分程度がお勧めです（それ以上長いと授業時間内では終わりません）。"
      ],
      "metadata": {
        "id": "ZCrDrg9wzCiz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 動画の取得\n",
        "\n",
        "※ 自分で動画が用意できる人は、左のパネルを「ファイル」にした上で video.mp4 という名前にした動画ファイルをドラッグして置いてください。\n",
        "\n",
        "以下では、Youtube から数分の動画をダウンロードして必要な部分（20秒程度）を切り出します。\n",
        "\n",
        "*   下記の url 変数に設置したい動画の URL を記述します。\n",
        "*   下記の start_time に切り出したい開始時間を記入します。\n",
        "*   下記の duration に何秒間分切り出すかを記入します。"
      ],
      "metadata": {
        "id": "CXlKzzTIze9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /content/video_org.mp4\n",
        "!pip install youtube-dl\n",
        "import youtube_dl\n",
        "\n",
        "# 例１：野球\n",
        "url = 'https://www.youtube.com/watch?v=VCHl3Yrnfjs' \n",
        "start_time = \"00:00:06\"\n",
        "duration = \"00:00:20\"\n",
        "\n",
        "# 例２：バイク\n",
        "#url = 'https://www.youtube.com/watch?v=wnRH3-CIk4I' \n",
        "#start_time = \"00:00:10\"\n",
        "#duration = \"00:00:20\"\n",
        "\n",
        "vdl_opts = {'outtmpl':'/content/video_org.mp4', 'format':'bestvideo'}\n",
        "vdl = youtube_dl.YoutubeDL(vdl_opts)\n",
        "vdl.extract_info(url)\n",
        "\n",
        "!yes|ffmpeg -ss $start_time -i \"/content/video_org.mp4\" -t $duration -c copy \"/content/video.mp4\""
      ],
      "metadata": {
        "id": "cNJ-IJmm5y0Q",
        "outputId": "47934ff0-1ccc-4e07-c372-9991200cf666",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[download]  23.6% of 50.60MiB at 80.92KiB/s ETA 08:09"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 物体追跡\n",
        "ここでやっていること：動画を１フレームずつに分けて物体検出をし、結果を統合して動画を作り直します。"
      ],
      "metadata": {
        "id": "BG8NRBrGfAfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = '/content/img'\n",
        "if not os.path.exists(img_path):\n",
        "  os.mkdir(img_path)\n",
        "!rm /content/img/*\n",
        "\n",
        "videopath = '/content/video.mp4'\n",
        "\n",
        "import cv2\n",
        "from IPython.display import clear_output\n",
        "\n",
        "cmap = plt.get_cmap('tab20b')\n",
        "colors = [cmap(i)[:3] for i in np.linspace(0, 1, 20)]\n",
        "\n",
        "# initialize Sort object and video capture\n",
        "from sort import *\n",
        "vid = cv2.VideoCapture(videopath)\n",
        "mot_tracker = Sort() \n",
        "ii = 0\n",
        "while(True):\n",
        "    ret, frame = vid.read()\n",
        "    if ret == False:\n",
        "        break\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    pilimg = Image.fromarray(frame)\n",
        "    detections = detect_image(pilimg)\n",
        "\n",
        "    img = np.array(pilimg)\n",
        "    pad_x = max(img.shape[0] - img.shape[1], 0) * (img_size / max(img.shape))\n",
        "    pad_y = max(img.shape[1] - img.shape[0], 0) * (img_size / max(img.shape))\n",
        "    unpad_h = img_size - pad_y\n",
        "    unpad_w = img_size - pad_x\n",
        "    if detections is not None:\n",
        "        tracked_objects = mot_tracker.update(detections.cpu())\n",
        "\n",
        "        unique_labels = detections[:, -1].cpu().unique()\n",
        "        n_cls_preds = len(unique_labels)\n",
        "        for x1, y1, x2, y2, obj_id, cls_pred in tracked_objects:\n",
        "            box_h = int(((y2 - y1) / unpad_h) * img.shape[0])\n",
        "            box_w = int(((x2 - x1) / unpad_w) * img.shape[1])\n",
        "            y1 = int(((y1 - pad_y // 2) / unpad_h) * img.shape[0])\n",
        "            x1 = int(((x1 - pad_x // 2) / unpad_w) * img.shape[1])\n",
        "\n",
        "            color = colors[int(obj_id) % len(colors)]\n",
        "            color = [i * 255 for i in color]\n",
        "            cls = classes[int(cls_pred)]\n",
        "            cv2.rectangle(frame, (x1, y1), (x1+box_w, y1+box_h), color, 4)\n",
        "            cv2.rectangle(frame, (x1, y1-35), (x1+len(cls)*19+60, y1), color, -1)\n",
        "            cv2.putText(frame, cls + \"-\" + str(int(obj_id)), (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 3)\n",
        "    ii = ii + 1\n",
        "    #print(\"ii=\", ii)\n",
        "    frame = cv2.cvtColor(frame.astype(np.float32), cv2.COLOR_RGB2BGR)\n",
        "    cv2.imwrite(\"/content/img/\" + str(ii).zfill(5) + \".jpg\", frame)"
      ],
      "metadata": {
        "id": "lgDvIkKirekP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 全てのフレームを結合して動画にする"
      ],
      "metadata": {
        "id": "E4cDfdFae19O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yes|ffmpeg -r 30 -i '/content/img/%05d.jpg' -vcodec libx264 -pix_fmt yuv420p -r 30 '/content/tracking.mp4'"
      ],
      "metadata": {
        "id": "4H20fA6fJj2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## トラッキング結果（動画）の表示"
      ],
      "metadata": {
        "id": "mRg0tbJ-hGuE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "この画面で再生できるようにしましたが、防大だと回線が細くてカクカクです。うまく見られない場合は、画面左端のフォルダのマークをクリックすると今回使用したファイルの一覧が出ます。\n",
        "\n",
        "\n",
        "*   video_org.mp4: ダウンロードしたオリジナルの動画\n",
        "*   video.mp4: 必要な秒数だけ抜き出した動画\n",
        "*   tracking.mp4: トラッキング結果の動画\n",
        "\n",
        "各動画をダウンロードして手元で見てください。\n",
        "\n"
      ],
      "metadata": {
        "id": "TCGNszo_w3uD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "video_path = \"/content/tracking.mp4\"\n",
        " \n",
        "def show_video(video_path, video_width = 600):\n",
        "   \n",
        "  video_file = open(video_path, \"r+b\").read()\n",
        " \n",
        "  video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
        "  return HTML(f\"\"\"<video width={video_width} controls><source src=\"{video_url}\"></video>\"\"\")\n",
        " \n",
        "show_video(video_path)"
      ],
      "metadata": {
        "id": "JJQwT9hj_VL_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}