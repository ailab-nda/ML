{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP6zxPxdGRC8KGTTBryEL/I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ailab-nda/ML/blob/main/ELYZA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 準備\n",
        "長いテキストを折り返し表示させる命令"
      ],
      "metadata": {
        "id": "bG5W8lTrtIQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "id": "TG6sUBaNhHaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 大規模言語モデルの実習\n",
        "chatGPT が禁止なので、Llama 2 を使います。"
      ],
      "metadata": {
        "id": "WmIwV9iVeEkN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Llama 2とは\n",
        "Llama 2とは、2023年7月18日にMeta社が公開した英語ベースの大規模言語モデルです。先に公開された「LLaMA」が研究用途に限定されていたのに対し、Llama 2は商用利用も可能となっています。公開されているモデルとしてはとても性能が高いことから、OpenAIのGPT-4やGoogleのPaLMなどのクローズドなLLMと競合する形で、英語圏では既にオープンモデルのデファクトスタンダードとなりつつあります。\n",
        "\n",
        "サイズは70億、130億、700億の3種類となっており、いずれのモデルも教師ありファインチューニング（Supervised Fine-Tuning、SFT）及び、人間からのフィードバックに基づいた強化学習（Reinforcement Learning from Human Feedback、RLHF）を施したchatモデルも同時に公開しています。\n"
      ],
      "metadata": {
        "id": "bWnHDwsKdDG1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ELYZA-japanese-Llama-2-7b とは\n",
        "\n",
        "「ELYZA-japanese-Llama-2-7b」は、東京大学松尾研究室発・AIスタートアップの「ELYZA」が開発した、日本語LLMです。Metaの「Llama 2」をベースに、日本語による追加事前学習を行なった日本語言語モデル「ELYZA-japanese-Llama-2-7b」と、そこにELYZA独自の事後学習を施した「ELYZA-japanese-Llama-2-7b-instruct」、日本語の語彙追加により高速化を行った「ELYZA-japanese-Llama-2-7b-fast / ELYZA-japanese-Llama-2-7b-fast-instruct」を一般公開しました。いずれも70億パラメータのモデルで、公開されている日本語のLLMとしては最大級の規模です。\n",
        "\n",
        "ライセンスはLlama 2 Community License に準拠しており、Acceptable Use Policy に従う限りにおいては、研究および商業目的での利用が可能です。"
      ],
      "metadata": {
        "id": "y3WMcln0dl1g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### パッケージのインストール"
      ],
      "metadata": {
        "id": "E2iN_zNdeVHy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NA8ny83OdA6G"
      },
      "outputs": [],
      "source": [
        "!pip install transformers accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### トークナイザーとモデルの準備。\n",
        "今回は、高速な指示モデル (elyza/ELYZA-japanese-Llama-2-7b-fast-instruct) を利用しています。"
      ],
      "metadata": {
        "id": "13A2YXsJeopE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# トークナイザーとモデルの準備\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"elyza/ELYZA-japanese-Llama-2-7b-instruct\"\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"elyza/ELYZA-japanese-Llama-2-7b-instruct\",\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")"
      ],
      "metadata": {
        "id": "WaHllIaWeRPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### プロンプトの書式\n",
        "\n",
        "```\n",
        "<s>[INST] <<SYS>>\n",
        "{システムメッセージ}\n",
        "<</SYS>>\n",
        "{ユーザーメッセージ}[/INST]\n",
        "```"
      ],
      "metadata": {
        "id": "3eSxDye3e3Xu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### テキスト生成"
      ],
      "metadata": {
        "id": "rUc32u0AgK8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextIteratorStreamer\n",
        "from threading import Thread\n",
        "\n",
        "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
        "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
        "DEFAULT_SYSTEM_PROMPT = \"あなたは誠実で優秀な日本人のアシスタントです。\"\n",
        "\n",
        "# ストリーミング出力\n",
        "def ask(text):\n",
        "    prompt = \"{bos_token}{b_inst} {system}{prompt} {e_inst} \".format(\n",
        "        bos_token=tokenizer.bos_token,\n",
        "        b_inst=B_INST,\n",
        "        system=f\"{B_SYS}{DEFAULT_SYSTEM_PROMPT}{E_SYS}\",\n",
        "        prompt=text,\n",
        "        e_inst=E_INST,\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        streamer = TextIteratorStreamer(tokenizer)\n",
        "        token_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
        "        generation_kwargs = dict(\n",
        "            input_ids=token_ids.to(model.device),\n",
        "            max_new_tokens=1024,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "            streamer=streamer,\n",
        "        )\n",
        "        thread = Thread(target=model.generate, kwargs=generation_kwargs)\n",
        "        thread.start()\n",
        "\n",
        "    for new_text in streamer:\n",
        "        print(new_text.replace(\"[/INST]\", \"[/INST]\\n\\n\"), end=\"\")"
      ],
      "metadata": {
        "id": "Qpwkxxk4x2W4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.generation_config"
      ],
      "metadata": {
        "id": "YXWnAkCsB2Wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 質問と答えの例"
      ],
      "metadata": {
        "id": "LciEm1cRBqgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ask(\"横須賀市の観光プランを考えて下さい。\")"
      ],
      "metadata": {
        "id": "IN5j7SgZ45JQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ask(\"カレーの作り方を教えて下さい。\")"
      ],
      "metadata": {
        "id": "dgnj4_864-nN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 英語で聞くと英語で返してくる"
      ],
      "metadata": {
        "id": "cvCnJHO1BZTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ask(\"Please answer the following quiz question. The combined price of a ballpoint pen and an eraser is 110 yen. The ballpoint pen is 100 yen more expensive than the eraser. So, what is the price of the eraser?\")"
      ],
      "metadata": {
        "id": "opkOI_YF_-1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 複数行の文字列は \"\"\" を使う"
      ],
      "metadata": {
        "id": "jdeV7-DvBGQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ask(\"\"\"以下の選択肢の中で、日本が発祥とされ、世界中で知られている食べ物は何でしょうか？\n",
        "\n",
        "A. ピザ\n",
        "B. パスタ\n",
        "C. ハンバーガー\n",
        "D. 寿司\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "LF-nKu5aA2OG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 小説も書く"
      ],
      "metadata": {
        "id": "tKN1CmstBmi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ask(\"クマが海辺に行ってアザラシと友達になり、最終的には家に帰るというプロットの短編小説を書いてください。\")"
      ],
      "metadata": {
        "id": "ZQIK6vGyydom"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}