{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tn-3Npwk3ADG"
      },
      "source": [
        "https://colab.research.google.com/github/ailab-nda/NLP/blob/main/GPT_2.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySRmF_wbrvCI"
      },
      "source": [
        "# GPT-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXAtAGpYEn21"
      },
      "source": [
        "## 日本語モデルの使用"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99jvcYWZruK4"
      },
      "source": [
        "# Huggingface Transformersのインストール\n",
        "!pip install transformers==4.4.2\n",
        "\n",
        "# Sentencepieceのインストール\n",
        "!pip install sentencepiece==0.1.91"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQxuuEh8rxwp"
      },
      "source": [
        "from transformers import T5Tokenizer, AutoModelForCausalLM\n",
        "\n",
        "# トークナイザーとモデルの準備\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"rinna/japanese-gpt2-medium\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"rinna/japanese-gpt2-medium\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slR0XH_UsWtz"
      },
      "source": [
        "# 推論\n",
        "input = tokenizer.encode(\"今朝未明、東京新宿区の路上で、\", return_tensors=\"pt\")\n",
        "output = model.generate(input, do_sample=True, max_length=30, num_return_sequences=3)\n",
        "print(tokenizer.batch_decode(output))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}